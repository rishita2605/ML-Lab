{"cells":[{"cell_type":"code","execution_count":1,"id":"4dfbec0c","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1626,"status":"ok","timestamp":1637727087840,"user":{"displayName":"Preethi Sheba Hepsiba","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqnC4vB54qacgOTHQTCnLznCXG5cFK4s-i_Bf_7w=s64","userId":"04530026991878723591"},"user_tz":-330},"id":"4dfbec0c","outputId":"07a0ed8c-68a6-42fb-ea76-55334945e436"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.66666667 1.        ]\n"," [0.33333333 0.55555556]\n"," [1.         0.66666667]]\n","[[0.92]\n"," [0.86]\n"," [0.89]]\n"]}],"source":["import numpy as np\n","X = np.array(([2, 9], [1, 5], [3, 6]), dtype=float) #attribute here we've 2 attributes i.e sleep & study\n","Y = np.array(([92], [86], [89]), dtype=float) #o/p i.e marks\n","X = X/np.amax(X, axis=0) #normalising the attributes by dividing with max from each column\n","actual_output = Y / 100 #normalising the marks by dividing by max marks i.e 100\n","print(X)\n","print(actual_output)"]},{"cell_type":"code","execution_count":2,"id":"0b69ca48","metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1637727087842,"user":{"displayName":"Preethi Sheba Hepsiba","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqnC4vB54qacgOTHQTCnLznCXG5cFK4s-i_Bf_7w=s64","userId":"04530026991878723591"},"user_tz":-330},"id":"0b69ca48"},"outputs":[],"source":["def sigmoid(x):\n","    return 1/(1 + np.exp(-x))\n","\n","def derivatives_sigmoid(x):\n","    return x * (1 - x)\n"]},{"cell_type":"code","execution_count":3,"id":"06af4aee","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1637727087843,"user":{"displayName":"Preethi Sheba Hepsiba","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqnC4vB54qacgOTHQTCnLznCXG5cFK4s-i_Bf_7w=s64","userId":"04530026991878723591"},"user_tz":-330},"id":"06af4aee","outputId":"29332a10-4d72-4ce9-e099-8ab4494cb3d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[-0.0010569  -0.02792123  0.01036891]\n"," [-0.02806564 -0.0461448  -0.01778802]]\n","bias  [[0.03978166 0.01560739 0.01605434]]\n"]}],"source":["#initialization\n","epoch = 1000\n","learning_rate = 0.15\n","inputlayer_neurons = 2 #acc to no. of i/p (2 param here)\n","hiddenlayer_neurons = 3 \n","outputlayer_neurons = 1 #acc to no. of o/p (marks)\n","\n","#assigning random weights & biases\n","\n","# Weight of hidden layer\n","wh = np.random.uniform(low=-0.05,high=0.05,size=(inputlayer_neurons, hiddenlayer_neurons))#2(rows)x3(cols)\n","#wh[0][1] -> weight of i/p layer 0 with the hidden layer 1\n","print(wh)\n","\n","# Bias of hidden layer\n","bh = np.random.uniform(low=-0.05,high=0.05,size=(1, hiddenlayer_neurons))\n","print('bias ',bh)\n","# Weight of output layer\n","wo = np.random.uniform(low=-0.05,high=0.05, size=(hiddenlayer_neurons, outputlayer_neurons))\n","\n","# Bias of output layer\n","bo = np.random.uniform(low=-0.05,high=0.05,size=(1, outputlayer_neurons))"]},{"cell_type":"code","execution_count":4,"id":"0d2e6e14","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4827,"status":"ok","timestamp":1637727092644,"user":{"displayName":"Preethi Sheba Hepsiba","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqnC4vB54qacgOTHQTCnLznCXG5cFK4s-i_Bf_7w=s64","userId":"04530026991878723591"},"user_tz":-330},"id":"0d2e6e14","outputId":"2c63f22f-6e82-4218-e066-8f80f859fe06"},"outputs":[],"source":["# training\n","for i in range(epoch):\n","    # Sum of (input * weights in hidden layer) + bias of hidden\n","    net_h = np.dot(X, wh) + bh # net of 1 layer -> Î£w*x + b (doing sum of all layers)\n","    # print('net h',net_h)\n","\n","    # Apply Activation Function\n","    sigma_h = sigmoid(net_h)\n","    # Input to O/P Layer = (O/P of Hidden Layer * weight of O/P Layer) + bias of O/P layer\n","    net_o = np.dot(sigma_h, wo) + bo\n","    # Apply Activation Function\n","    output = sigmoid(net_o)\n","    \n"," #Backpropagation\n"," # Error at Output layer\n","    eo = actual_output-output # Error at o/p\n","    outgrad = derivatives_sigmoid(output)\n","    d_output = eo * outgrad # Errj=Oj(1-Oj)(Tj-Oj)\n","    #print(\"the d_output is\",d_output)\n","\n","# Error at Hidden later\n","    eh = d_output.dot(wo.T) # .T means transpose\n","    hiddengrad = derivatives_sigmoid(sigma_h) # How much hidden layer wts contributed to error\n","    d_hidden = eh * hiddengrad\n","    \n","    wo += sigma_h.T.dot(d_output) * learning_rate # Dotproduct of nextlayererror and currentlayerop\n","    wh += X.T.dot(d_hidden) * learning_rate\n","    \n","    sum_error = 0\n","    \n","    for j in range(len(actual_output)):\n","        # print(output[j],actual_output[j] )\n","        sum_error+=((output[j] - actual_output[j])**2)\n","    sum_error /= 2\n","    \n","    # print(f'Epoch {i} error {sum_error}')\n","\n"]},{"cell_type":"code","execution_count":5,"id":"1f4b1235","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":61,"status":"ok","timestamp":1637727092645,"user":{"displayName":"Preethi Sheba Hepsiba","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqnC4vB54qacgOTHQTCnLznCXG5cFK4s-i_Bf_7w=s64","userId":"04530026991878723591"},"user_tz":-330},"id":"1f4b1235","outputId":"260fdeb1-6bb5-47c5-ba61-6cb309e46cd0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Normalized Input: \n","[[0.66666667 1.        ]\n"," [0.33333333 0.55555556]\n"," [1.         0.66666667]]\n","Actual Output: \n","[[0.92]\n"," [0.86]\n"," [0.89]]\n","Predicted Output: \n"," [[0.89539893]\n"," [0.87974221]\n"," [0.8948854 ]]\n"]}],"source":["print(\"Normalized Input: \\n\" + str(X))\n","print(\"Actual Output: \\n\" + str(actual_output))\n","print(\"Predicted Output: \\n\" ,output)"]},{"cell_type":"code","execution_count":6,"id":"b7a1a8d6","metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1637727092646,"user":{"displayName":"Preethi Sheba Hepsiba","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjqnC4vB54qacgOTHQTCnLznCXG5cFK4s-i_Bf_7w=s64","userId":"04530026991878723591"},"user_tz":-330},"id":"b7a1a8d6"},"outputs":[{"name":"stdout","output_type":"stream","text":["amax  [3 6 9]\n","array([[ 8, 10],\n","       [12, 15]])\n","array([[10, 13],\n","       [14, 18]])\n"]}],"source":["import numpy as np\n","from pprint import pprint\n","arr = np.array([[1,2,3],[4,5,6], [7,8,9]])\n","maximum = np.amax(arr, axis = 1)\n","print('amax ',maximum)\n","\n","arr1 = [[2],[3]]\n","arr2 = [[4, 5]]\n","\n","dotproduct = np.dot(arr1, arr2)\n","pprint(dotproduct)\n","\n","\"\"\" def square(x):\n","  return x**2\n","\n","sq = square(dotproduct)\n","pprint(sq) \"\"\"\n","\n","sumdot = dotproduct + [2,3]\n","pprint(sumdot)"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"BackPropagation.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":5}
