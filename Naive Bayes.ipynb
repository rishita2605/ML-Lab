{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "29540dc2",
   "metadata": {
    "id": "29540dc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       6    148    72    35      0  33.6  0.627    50    1\n",
      "564  2.0   95.0  54.0  14.0   88.0  26.1  0.748  22.0  0.0\n",
      "470  0.0  137.0  70.0  38.0    0.0  33.2  0.170  22.0  0.0\n",
      "719  4.0   83.0  86.0  19.0    0.0  29.3  0.317  34.0  0.0\n",
      "632  1.0  128.0  82.0  17.0  183.0  27.5  0.115  22.0  0.0\n",
      "260  3.0  141.0   0.0   0.0    0.0  30.0  0.761  27.0  1.0\n",
      "..   ...    ...   ...   ...    ...   ...    ...   ...  ...\n",
      "277  5.0  114.0  74.0   0.0    0.0  24.9  0.744  57.0  0.0\n",
      "308  2.0  124.0  68.0  28.0  205.0  32.9  0.875  30.0  1.0\n",
      "148  2.0   90.0  70.0  17.0    0.0  27.3  0.085  22.0  0.0\n",
      "339  1.0  130.0  70.0  13.0  105.0  25.9  0.472  22.0  0.0\n",
      "673  8.0   91.0  82.0   0.0    0.0  35.6  0.587  68.0  0.0\n",
      "\n",
      "[614 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "filename = 'pima-indians-diabetes.csv'\n",
    "# filename = 'test.csv'\n",
    "import pandas as pd\n",
    "# import numpy as np\n",
    "\n",
    "df= pd.read_csv(filename)\n",
    "df = df.astype(float) #converting all columns to float type\n",
    "\n",
    "train=df.sample(frac=0.8,random_state=105) #random state is a seed value\n",
    "print(train) #train.index gives the index of all the data-rows included in train\n",
    "test=df.drop(train.index) #dropping those indices which are in train (keeping the remaining in test)\n",
    "# print(test) \n",
    "# columns ['Pregnancies','Glucose','BP','SkinThickness','Insulin','BMI','DiabetesPedigree','Age','Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d0628be2",
   "metadata": {
    "id": "d0628be2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------outcome_group for 0.0 ----------------------------------------------\n",
      "attribute list ->\n",
      "[[3.2896039603960396, 3.0378572247064866], [110.16831683168317, 25.004047039945263], [67.97524752475248, 17.618211342424104], [19.849009900990097, 14.966446309872751], [69.43069306930693, 95.56208353704045], [30.350000000000005, 7.906445842227683], [0.4308465346534654, 0.2934411075258142], [31.094059405940595, 11.620810645390257]]\n",
      "summaries -> \n",
      "dict_keys([0.0])\n",
      "-----------------------------------------------outcome_group for 1.0 ----------------------------------------------\n",
      "attribute list ->\n",
      "[[4.766666666666667, 3.6138798529705634], [141.78095238095239, 33.11744533763891], [72.01904761904763, 19.986589260922006], [23.166666666666668, 16.87204401424145], [103.60952380952381, 140.61393039391504], [35.352380952380955, 7.208482446696007], [0.5614809523809524, 0.3477006110815123], [37.08571428571429, 10.782862786390721]]\n",
      "summaries -> \n",
      "dict_keys([0.0, 1.0])\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "# group by outcomes, in the train group i.e all ones together & zeroes together\n",
    "from pprint import pprint\n",
    "outcome_group = train.groupby(df.columns[-1])\n",
    "# print(outcome_group.size()) #displays the first row(as tags)\n",
    "n_attr = len(df.columns) - 1 #-1 to remove the count of 0 & 1 (result) (8 here)\n",
    "\n",
    "summaries = {}\n",
    "#summarize by outcome, find mean and std deviation of each outcome.\n",
    "for classValue, instances in outcome_group:\n",
    "    #class Value is 0 or 1, instances are - all instances in each group\n",
    "    #loop runs only twice, once of 1 and once for 0\n",
    "    print(f'-----------------------------------------------outcome_group for {classValue} ----------------------------------------------')\n",
    "    # pprint(list(instances.mean(axis=0)))\n",
    "    attr_mv=[]\n",
    "    mean=list(instances.mean(axis=0).values)\n",
    "    stdev=list(instances.std(axis=0).values)\n",
    "    # print(f'instances->\\n{instances} \\nmean -> {len(mean)}')\n",
    "    #for loop because all instances(columns) are together, can't separate them\n",
    "    for i in range(n_attr):\n",
    "        attr_mv.append([mean[i],stdev[i]]) #for each attribute value we have an array consisting of std dev & mean\n",
    "    print(f'attribute list ->\\n{attr_mv}')   \n",
    "    summaries[classValue]=attr_mv\n",
    "    print(f'summaries -> \\n{summaries.keys()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6ed6add7",
   "metadata": {
    "id": "6ed6add7"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def calculateProb(x, mean, stdev):\n",
    "    exponent = math.exp(-math.pow(x-mean,2)/(2*math.pow(stdev,2)))\n",
    "    return (1 / (math.sqrt(2*math.pi)*math.pow(stdev,2))) * exponent\n",
    "  \n",
    "\n",
    "def calculateClassProb(summaries, X_vec):\n",
    "    probabilities = {}\n",
    "    for classValue, classSummaries in summaries.items():\n",
    "        probabilities[classValue] = 1\n",
    "        \n",
    "        # print('class summaries\\n', classSummaries)\n",
    "        # print('length\\n', len(classSummaries))\n",
    "\n",
    "        #calculating probablity of each attribute and multiplying them. \n",
    "        for i in range(len(classSummaries)):\n",
    "            mean, stdev = classSummaries[i]\n",
    "            x = X_vec[i]\n",
    "            probabilities[classValue] *= calculateProb(x, mean, stdev) # multiplying because conditionally independent\n",
    "            \n",
    "    return probabilities\n",
    "    \n",
    "def predict(summaries, X_vec):\n",
    "    prob = calculateClassProb(summaries, X_vec)\n",
    "    bestLabel, bestProb = None, -1\n",
    "\n",
    "    # print(f'\\n\\n probablity {prob}')                \n",
    "\n",
    "    #in this case we could have directly compared. But, when there are more than 2 classes(yes/no/maybe?) we need to select the best/largest \n",
    "    for classValue, probability in prob.items():\n",
    "        if bestLabel is None or probability > bestProb:\n",
    "            bestProb = probability\n",
    "            bestLabel = classValue\n",
    "    return bestLabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dc34e58b",
   "metadata": {
    "id": "dc34e58b"
   },
   "outputs": [],
   "source": [
    "# test model\n",
    "predictions = []\n",
    "testSet=test.values.tolist()\n",
    "# pprint(summaries)\n",
    "for i in range(len(testSet)):\n",
    "    result = predict(summaries, testSet[i]) #summaries - mean & std dev of test dataset\n",
    "    predictions.append(result)\n",
    "#print(f'predictions -> {predictions}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2d6c02b9",
   "metadata": {
    "id": "2d6c02b9",
    "outputId": "91c71351-162b-4c98-9d5e-4a319ba5609b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 767 rows into train=614 and test=153\n",
      "Accuracy: 74.50980392156863\n"
     ]
    }
   ],
   "source": [
    "def getAccuracy(test, predictions):\n",
    "    correct = 0\n",
    "    # pprint(test)\n",
    "    # print(test.iloc[1, -1])\n",
    "    for i in range(len(test)):\n",
    "        if test.iloc[i,-1] == predictions[i]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(testSet))) * 100.0\n",
    "\n",
    "accuracy = getAccuracy(test, predictions)\n",
    "print(f'Split {len(df)} rows into train={len(train)} and test={len(test)}')\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b77e90",
   "metadata": {
    "id": "d3b77e90"
   },
   "source": [
    "<h2>Using sci-kit-learn Gaussian NB</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f992f724",
   "metadata": {
    "id": "f992f724",
    "outputId": "854bb402-3288-4465-aa99-a501b5004027"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_30360/754854351.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mgnb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "data_train = train.iloc[:,:-1]\n",
    "target_train  = train.iloc[:,-1]\n",
    "gnb.fit(data_train, target_train)\n",
    "\n",
    "data_test = test.iloc[:,:-1]\n",
    "target_test = test.iloc[:, -1]\n",
    "y_pred = gnb.predict(data_test)\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "#Model Accuracy, how often is the classifier correct?\n",
    "print(f'Split {len(df)} rows into train={len(data_train)} and test={len(data_test)}')\n",
    "print(\"Accuracy:\",(metrics.accuracy_score(test.iloc[:,-1], y_pred)*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee68db92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       6    148    72    35      0  33.6  0.627    50    1\n",
      "564  2.0   95.0  54.0  14.0   88.0  26.1  0.748  22.0  0.0\n",
      "470  0.0  137.0  70.0  38.0    0.0  33.2  0.170  22.0  0.0\n",
      "719  4.0   83.0  86.0  19.0    0.0  29.3  0.317  34.0  0.0\n",
      "632  1.0  128.0  82.0  17.0  183.0  27.5  0.115  22.0  0.0\n",
      "260  3.0  141.0   0.0   0.0    0.0  30.0  0.761  27.0  1.0\n",
      "..   ...    ...   ...   ...    ...   ...    ...   ...  ...\n",
      "277  5.0  114.0  74.0   0.0    0.0  24.9  0.744  57.0  0.0\n",
      "308  2.0  124.0  68.0  28.0  205.0  32.9  0.875  30.0  1.0\n",
      "148  2.0   90.0  70.0  17.0    0.0  27.3  0.085  22.0  0.0\n",
      "339  1.0  130.0  70.0  13.0  105.0  25.9  0.472  22.0  0.0\n",
      "673  8.0   91.0  82.0   0.0    0.0  35.6  0.587  68.0  0.0\n",
      "\n",
      "[614 rows x 9 columns]\n",
      "data\n",
      "        6    148    72    35      0  33.6  0.627    50\n",
      "564  2.0   95.0  54.0  14.0   88.0  26.1  0.748  22.0\n",
      "470  0.0  137.0  70.0  38.0    0.0  33.2  0.170  22.0\n",
      "719  4.0   83.0  86.0  19.0    0.0  29.3  0.317  34.0\n",
      "632  1.0  128.0  82.0  17.0  183.0  27.5  0.115  22.0\n",
      "260  3.0  141.0   0.0   0.0    0.0  30.0  0.761  27.0\n",
      "..   ...    ...   ...   ...    ...   ...    ...   ...\n",
      "277  5.0  114.0  74.0   0.0    0.0  24.9  0.744  57.0\n",
      "308  2.0  124.0  68.0  28.0  205.0  32.9  0.875  30.0\n",
      "148  2.0   90.0  70.0  17.0    0.0  27.3  0.085  22.0\n",
      "339  1.0  130.0  70.0  13.0  105.0  25.9  0.472  22.0\n",
      "673  8.0   91.0  82.0   0.0    0.0  35.6  0.587  68.0\n",
      "\n",
      "[614 rows x 8 columns]\n",
      "target\n",
      " 564    0.0\n",
      "470    0.0\n",
      "719    0.0\n",
      "632    0.0\n",
      "260    1.0\n",
      "      ... \n",
      "277    0.0\n",
      "308    1.0\n",
      "148    0.0\n",
      "339    0.0\n",
      "673    0.0\n",
      "Name: 1, Length: 614, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train)\n",
    "data_train = train.iloc[:,:-1]\n",
    "print('data\\n',data_train)\n",
    "target_train  = train.iloc[:,-1]\n",
    "print('target\\n',target_train)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "NB.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
