{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29540dc2",
   "metadata": {
    "id": "29540dc2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6    148    72    35      0  33.6  0.627    50    1\n",
      "6  10.0  115.0   0.0   0.0    0.0  35.3  0.134  29.0  0.0\n",
      "2   1.0   89.0  66.0  23.0   94.0  28.1  0.167  21.0  0.0\n",
      "3   0.0  137.0  40.0  35.0  168.0  43.1  2.288  33.0  1.0\n",
      "7   2.0  197.0  70.0  45.0  543.0  30.5  0.158  53.0  1.0\n",
      "4   5.0  116.0  74.0   0.0    0.0  25.6  0.201  30.0  0.0\n",
      "1   8.0  183.0  64.0   0.0    0.0  23.3  0.672  32.0  1.0\n"
     ]
    }
   ],
   "source": [
    "# filename = 'pima-indians-diabetes.csv'\n",
    "filename = 'test.csv'\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df= pd.read_csv(filename)\n",
    "df = df.astype(float) #converting all columns to float type\n",
    "\n",
    "train=df.sample(frac=0.8,random_state=105) #random state is a seed value\n",
    "print(train) #train.index gives the index of all the data-rows included in train\n",
    "test=df.drop(train.index) #dropping those indices which are in train (keeping the remaining in test)\n",
    "# print(test) \n",
    "# columns ['Pregnancies','Glucose','BP','SkinThickness','Insulin','BMI','DiabetesPedigree','Age','Outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0628be2",
   "metadata": {
    "id": "d0628be2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6    148    72    35     0  33.6  0.627    50    1\n",
      "6  10.0  115.0   0.0   0.0   0.0  35.3  0.134  29.0  0.0\n",
      "2   1.0   89.0  66.0  23.0  94.0  28.1  0.167  21.0  0.0\n",
      "4   5.0  116.0  74.0   0.0   0.0  25.6  0.201  30.0  0.0\n",
      "[5.333333333333333,\n",
      " 106.66666666666667,\n",
      " 46.666666666666664,\n",
      " 7.666666666666667,\n",
      " 31.333333333333332,\n",
      " 29.666666666666668,\n",
      " 0.16733333333333333,\n",
      " 26.666666666666668,\n",
      " 0.0]\n",
      "     6    148    72    35      0  33.6  0.627    50    1\n",
      "3  0.0  137.0  40.0  35.0  168.0  43.1  2.288  33.0  1.0\n",
      "7  2.0  197.0  70.0  45.0  543.0  30.5  0.158  53.0  1.0\n",
      "1  8.0  183.0  64.0   0.0    0.0  23.3  0.672  32.0  1.0\n",
      "[3.3333333333333335,\n",
      " 172.33333333333334,\n",
      " 58.0,\n",
      " 26.666666666666668,\n",
      " 237.0,\n",
      " 32.3,\n",
      " 1.0393333333333332,\n",
      " 39.333333333333336,\n",
      " 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "# group by outcomes, in the train group i.e all ones together & zeroes together\n",
    "from pprint import pprint\n",
    "outcome_group = train.groupby(df.columns[-1])\n",
    "# print(outcome_group.size()) #displays the first row(as tags)\n",
    "n_attr = len(df.columns) - 1 #-1 to remove the count of 0 & 1 (result)\n",
    "\n",
    "summaries = {}\n",
    "#summarize by outcome, find mean and std deviation of each outcome.\n",
    "for classValue, instances in outcome_group:\n",
    "    #class Value is 0 or 1, instances are - all instances in each group\n",
    "    #loop runs only twice, once of 1 and once for 0\n",
    "    pprint(instances)\n",
    "    pprint(list(instances.mean(axis=0)))\n",
    "    attr_mv=[]\n",
    "    mean=list(instances.mean(axis=0).values)\n",
    "    stdev=list(instances.std(axis=0).values)\n",
    "\n",
    "    #for loop because all instances(columns) are together, can't separate them\n",
    "    for i in range(n_attr):\n",
    "        attr_mv.append([mean[i],stdev[i]]) #for each attribute value we have an array consisting of std dev & mean\n",
    "        \n",
    "    summaries[classValue]=attr_mv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ed6add7",
   "metadata": {
    "id": "6ed6add7"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def calculateProb(x, mean, stdev):\n",
    "    exponent = math.exp(-math.pow(x-mean,2)/(2*math.pow(stdev,2)))\n",
    "    return (1 / (math.sqrt(2*math.pi)*math.pow(stdev,2))) * exponent\n",
    "  \n",
    "\n",
    "def calculateClassProb(summaries, X_vec):\n",
    "    probabilities = {}\n",
    "    for classValue, classSummaries in summaries.items():\n",
    "        probabilities[classValue] = 1\n",
    "        \n",
    "        # print('class summaries\\n', classSummaries)\n",
    "        # print('length\\n', len(classSummaries))\n",
    "\n",
    "        #calculating probablity of each attribute and multiplying them. \n",
    "        for i in range(len(classSummaries)):\n",
    "            mean, stdev = classSummaries[i]\n",
    "            x = X_vec[i]\n",
    "            probabilities[classValue] *= calculateProb(x, mean, stdev)\n",
    "            \n",
    "    return probabilities\n",
    "    \n",
    "def predict(summaries, X_vec):\n",
    "    prob = calculateClassProb(summaries, X_vec)\n",
    "    bestLabel, bestProb = None, -1\n",
    "\n",
    "    # print('Probablitites-----------class\\n')\n",
    "    # pprint(prob)\n",
    "\n",
    "    #in this case we could have directly compared. But, when there are more than 2 classes(yes/no/maybe?) we need to select the best/largest \n",
    "    for classValue, probability in prob.items():\n",
    "        if bestLabel is None or probability > bestProb:\n",
    "            bestProb = probability\n",
    "            bestLabel = classValue\n",
    "    return bestLabel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc34e58b",
   "metadata": {
    "id": "dc34e58b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probablitites-----------class\n",
      "\n",
      "{0.0: 1.834672604102135e-24, 1.0: 1.1814708198750518e-24}\n",
      "Probablitites-----------class\n",
      "\n",
      "{0.0: 1.953179164869056e-19, 1.0: 6.571345077991297e-25}\n"
     ]
    }
   ],
   "source": [
    "# test model\n",
    "predictions = []\n",
    "testSet=test.values.tolist()\n",
    "# pprint(summaries)\n",
    "for i in range(len(testSet)):\n",
    "    result = predict(summaries, testSet[i]) #summaries - mean & std dev of test dataset\n",
    "    predictions.append(result)\n",
    "    # print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d6c02b9",
   "metadata": {
    "id": "2d6c02b9",
    "outputId": "91c71351-162b-4c98-9d5e-4a319ba5609b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 8 rows into train=6 and test=2\n",
      "Accuracy: 50.0\n"
     ]
    }
   ],
   "source": [
    "def getAccuracy(test, predictions):\n",
    "    correct = 0\n",
    "    # pprint(test)\n",
    "    # print(test.iloc[1, -1])\n",
    "    for i in range(len(test)):\n",
    "        if test.iloc[i,-1] == predictions[i]:\n",
    "            correct += 1\n",
    "    return (correct/float(len(testSet))) * 100.0\n",
    "\n",
    "accuracy = getAccuracy(test, predictions)\n",
    "print(f'Split {len(df)} rows into train={len(train)} and test={len(test)}')\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b77e90",
   "metadata": {
    "id": "d3b77e90"
   },
   "source": [
    "<h2>Using sci-kit-learn Gaussian NB</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f992f724",
   "metadata": {
    "id": "f992f724",
    "outputId": "854bb402-3288-4465-aa99-a501b5004027"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26960/988874574.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnaive_bayes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mgnb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGaussianNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "data_train = train.iloc[:,:-1]\n",
    "target_train  = train.iloc[:,-1]\n",
    "gnb.fit(data_train, target_train)\n",
    "\n",
    "data_test = test.iloc[:,:-1]\n",
    "y_pred = gnb.predict(data_test)\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "#Model Accuracy, how often is the classifier correct?\n",
    "print(f'Split {len(df)} rows into train={len(data_train)} and test={len(data_test)}')\n",
    "print(\"Accuracy:\",(metrics.accuracy_score(test.iloc[:,-1], y_pred)*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee68db92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      6    148    72    35      0  33.6  0.627    50    1\n",
      "6  10.0  115.0   0.0   0.0    0.0  35.3  0.134  29.0  0.0\n",
      "2   1.0   89.0  66.0  23.0   94.0  28.1  0.167  21.0  0.0\n",
      "3   0.0  137.0  40.0  35.0  168.0  43.1  2.288  33.0  1.0\n",
      "7   2.0  197.0  70.0  45.0  543.0  30.5  0.158  53.0  1.0\n",
      "4   5.0  116.0  74.0   0.0    0.0  25.6  0.201  30.0  0.0\n",
      "1   8.0  183.0  64.0   0.0    0.0  23.3  0.672  32.0  1.0\n",
      "data\n",
      "       6    148    72    35      0  33.6  0.627    50\n",
      "6  10.0  115.0   0.0   0.0    0.0  35.3  0.134  29.0\n",
      "2   1.0   89.0  66.0  23.0   94.0  28.1  0.167  21.0\n",
      "3   0.0  137.0  40.0  35.0  168.0  43.1  2.288  33.0\n",
      "7   2.0  197.0  70.0  45.0  543.0  30.5  0.158  53.0\n",
      "4   5.0  116.0  74.0   0.0    0.0  25.6  0.201  30.0\n",
      "1   8.0  183.0  64.0   0.0    0.0  23.3  0.672  32.0\n",
      "target\n",
      " 6    0.0\n",
      "2    0.0\n",
      "3    1.0\n",
      "7    1.0\n",
      "4    0.0\n",
      "1    1.0\n",
      "Name: 1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(train)\n",
    "data_train = train.iloc[:,:-1]\n",
    "print('data\\n',data_train)\n",
    "target_train  = train.iloc[:,-1]\n",
    "print('target\\n',target_train)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "NB.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
